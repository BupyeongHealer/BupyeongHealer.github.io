
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>PHIN</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://jonbarron.info/mipnerf360/img/gardenvase.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://bupyeonghealer.github.io/pond/"/>
    <meta property="og:title" content="PHIN: Pose-guided 3D Human Generation in Indoor Scene" />
    <meta property="og:description" content="In this work, we address the problem of scene-aware 3D human avatar generation based on human-scene interactions." />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="PHIN: Pose-guided 3D Human Generation in Indoor Scene" />
    <meta name="twitter:description" content="In this work, we address the problem of scene-aware 3D human avatar generation based on human-scene interactions." />
    <meta name="twitter:image" content="https://jonbarron.info/mipnerf360/img/gardenvase.jpg" />


<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ’«</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
<!--                 <b>Mip-NeRF 360</b>: Unbounded <br> Anti-Aliased Neural Radiance Fields</br>  -->
		    Pose-guided 3D Human Generation in Indoor Scene
		    <br>
                <small>
								AAAI 2023
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://bupyeonghealer.github.io/">
                          Minseok Kim
                        </a>
<!--                         </br>UNIST -->
                    </li>
                    <li>
                        <a href="https://github.com/Kang-ChangWoo">
                            Changwoo Kang
                        </a>
<!--                         </br>UNIST -->
                    </li>
                    <li>
                        <a href="https://github.com/Jeongin-park">
                          Jeongin Park
                        </a>
<!--                         </br>UNIST -->
                    </li>
                    <li>
                        <a href="http://rvi.unist.info//">
                          Kyungdon Joo
                        </a>
<!--                         </br>UNIST -->
                    </li>
                </ul>
		UNIST
            </div>
        </div>


        <div class="row">
                <div class="col-md-4 col-md-offset-4 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="https://bupyeonghealer.github.io/phin/">
                            <image src="img/paper_image.jpg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://bupyeonghealer.github.io/phin/">
                            <image src="img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                        <li>
                            <a href="https://bupyeonghealer.github.io/phin/" target="popup" onclick="window.open('https://bupyeonghealer.github.io/phin/','popup','width=600,height=400')">
                            <image src="img/database_icon.png" height="60px">
                                <h4><strong>Dataset</strong></h4>
                            </a>
                        </li>
<!--                         <li>
                            <a href="https://github.com/google-research/multinerf">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                            </a>
                        </li> -->
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/gardenvase_720.mp4" type="video/mp4" />
                </video>
						</div>
            <div class="col-md-8 col-md-offset-2">
							<p class="text-center">
								Results on the <em>unseen MP3D-R</em> data.
							</p>
						</div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
		In this work, we address the problem of scene-aware 3D human avatar generation based on human-scene interactions.
In particular, we pay attention to the fact that physical contact between 3D human and scene (<em>i.e., physical human-scene interactions</em>) requires geometrically aligned for natural 3D human avatar generation.
Motivated by this fact, we present a new 3D human generation framework that considers geometric alignment on potential contact areas between 3D human avatars and their surroundings.
In addition, we introduce a compact yet effective human pose classifier that classifies the human pose and provides potential contact areas of the 3D human avatar. 
It allows us to adaptively use geometric alignment loss according to the classified human pose.
Compared to the state-of-the-art method, our method can generate physically and semantically plausible 3D humans that interact naturally with 3D scenes without additional post-processing.
In our evaluations, we achieve the improvements with more plausible interactions and more variety of poses than prior research in qualitative and quantitative analysis.
                </p>
            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
			    coming soon!
<!--                         <iframe src="https://youtube.com/embed/zBSH-k9GbV4" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe> -->
                    </div>
                </div>
            </div>
        </div>

            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
			coming soon!
<!--                     <textarea id="bibtex" class="form-control" readonly>
@article{barron2022mipnerf360,
    title={Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields},
    author={Jonathan T. Barron and Ben Mildenhall and 
            Dor Verbin and Pratul P. Srinivasan and Peter Hedman},
    journal={CVPR},
    year={2022}
}</textarea> -->
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                This work was supported by Institute of Information & communications Technology Planning & Evaluation(IITP) grant funded by the Korea government(MSIT)(No.2020-0-01336, Artificial Intelligence Graduate School Program(UNIST)).
                    <br>
                The website template was borrowed from <a href="http://mgharbi.com/">MichaÃ«l Gharbi</a> and <a href="https://github.com/jonbarron/website">Jon Barron</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
